{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","spark.conf.set(\"sprk.sql.parquet.vorder.enabled\",\"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d0efd028-5e97-48c6-926c-4dbda580af1c","statement_id":3,"state":"finished","livy_statement_state":"available","queued_time":"2023-07-27T11:48:15.7685452Z","session_start_time":"2023-07-27T11:48:16.0485599Z","execution_start_time":"2023-07-27T11:48:26.8793666Z","execution_finish_time":"2023-07-27T11:48:28.9948574Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"6672e927-156c-4ac0-b1d0-c60ef434b962"},"text/plain":"StatementMeta(, d0efd028-5e97-48c6-926c-4dbda580af1c, 3, Finished, Available)"},"metadata":{}}],"execution_count":1,"metadata":{},"id":"6cd7c1d4-98e0-4d36-b3f4-504ae8faa8b6"},{"cell_type":"code","source":["df = spark.read.format(\"parquet\").load('Tables/Badges')\r\n","display(df.limit(10))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d0efd028-5e97-48c6-926c-4dbda580af1c","statement_id":4,"state":"finished","livy_statement_state":"available","queued_time":"2023-07-27T11:48:31.7305964Z","session_start_time":null,"execution_start_time":"2023-07-27T11:48:32.1319844Z","execution_finish_time":"2023-07-27T11:48:34.9879983Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":3,"UNKNOWN":0},"jobs":[{"displayName":"getRowsInJsonString at Display.scala:403","dataWritten":0,"dataRead":381,"rowCount":10,"usageDescription":"","jobId":10,"name":"getRowsInJsonString at Display.scala:403","description":"Job group for statement 4:\ndf = spark.read.format(\"parquet\").load('Tables/Badges')\ndisplay(df.limit(10))","submissionTime":"2023-07-27T11:48:34.025GMT","completionTime":"2023-07-27T11:48:34.085GMT","stageIds":[15,14],"jobGroup":"4","status":"SUCCEEDED","numTasks":6,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":5,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"getRowsInJsonString at Display.scala:403","dataWritten":381,"dataRead":14769387,"rowCount":4106,"usageDescription":"","jobId":9,"name":"getRowsInJsonString at Display.scala:403","description":"Job group for statement 4:\ndf = spark.read.format(\"parquet\").load('Tables/Badges')\ndisplay(df.limit(10))","submissionTime":"2023-07-27T11:48:33.475GMT","completionTime":"2023-07-27T11:48:33.973GMT","stageIds":[13],"jobGroup":"4","status":"SUCCEEDED","numTasks":5,"numActiveTasks":0,"numCompletedTasks":5,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":5,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":8,"name":"load at NativeMethodAccessorImpl.java:0","description":"Job group for statement 4:\ndf = spark.read.format(\"parquet\").load('Tables/Badges')\ndisplay(df.limit(10))","submissionTime":"2023-07-27T11:48:32.711GMT","completionTime":"2023-07-27T11:48:33.353GMT","stageIds":[12],"jobGroup":"4","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"44627da0-2a98-4e29-9339-270a6f4af16c"},"text/plain":"StatementMeta(, d0efd028-5e97-48c6-926c-4dbda580af1c, 4, Finished, Available)"},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.synapse.widget-view+json":{"widget_id":"3b148e3c-56aa-4d95-adbc-17b31f75eef6","widget_type":"Synapse.DataFrame"},"text/plain":"SynapseWidget(Synapse.DataFrame, 3b148e3c-56aa-4d95-adbc-17b31f75eef6)"},"metadata":{}}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"c1c0e78a-6e5c-48e0-9e11-f1664782bd8b\",\"activityId\":\"d0efd028-5e97-48c6-926c-4dbda580af1c\",\"applicationId\":\"application_1690455602133_0001\",\"jobGroupId\":\"4\",\"advices\":{\"warn\":1}}"},"collapsed":false},"id":"280eecc9-0913-4352-abe8-713f2bbd8bff"},{"cell_type":"code","source":["%%sql\r\n","SELECT * from Badges\r\n","LIMIT 10"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d0efd028-5e97-48c6-926c-4dbda580af1c","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2023-07-27T11:51:23.5966384Z","session_start_time":null,"execution_start_time":"2023-07-27T11:51:24.0280518Z","execution_finish_time":"2023-07-27T11:51:26.6323493Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":3,"UNKNOWN":0},"jobs":[{"displayName":"take at SQLInterpreter.scala:133","dataWritten":0,"dataRead":14767155,"rowCount":4096,"usageDescription":"","jobId":19,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 8:\nSELECT * from Badges\nLIMIT 10","submissionTime":"2023-07-27T11:51:25.164GMT","completionTime":"2023-07-27T11:51:25.501GMT","stageIds":[29],"jobGroup":"8","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":0,"dataRead":818,"rowCount":0,"usageDescription":"","jobId":18,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 8:\nSELECT * from Badges\nLIMIT 10","submissionTime":"2023-07-27T11:51:25.061GMT","completionTime":"2023-07-27T11:51:25.159GMT","stageIds":[28],"jobGroup":"8","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":1203,"rowCount":1,"usageDescription":"","jobId":17,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 8:\nSELECT * from Badges\nLIMIT 10: Filtering files for query","submissionTime":"2023-07-27T11:51:24.782GMT","completionTime":"2023-07-27T11:51:24.990GMT","stageIds":[27,26],"jobGroup":"8","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":2,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"1a334239-0bf4-41d4-8794-db1c80773e25"},"text/plain":"StatementMeta(, d0efd028-5e97-48c6-926c-4dbda580af1c, 8, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":6,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[{"name":"Id","type":"long","nullable":true,"metadata":{}},{"name":"Name","type":"string","nullable":false,"metadata":{}},{"name":"UserId","type":"long","nullable":true,"metadata":{}},{"name":"Date","type":"timestamp","nullable":false,"metadata":{}}]},"data":[["210312","Great Question","22656","2009-01-14T01:47:38Z"],["212842","Stellar Question","22656","2009-01-17T00:12:50Z"],["237576","generics","22656","2009-02-04T18:10:30Z"],["237577","linq","22656","2009-02-11T12:03:15Z"],["260322","vb.net","22656","2009-03-27T13:25:55Z"],["298540","performance","22656","2009-04-24T15:48:44Z"],["366516","linq","22656","2009-07-01T20:08:44Z"],["367882","reflection","22656","2009-06-30T15:11:41Z"],["371328","string","22656","2009-06-23T19:31:10Z"],["375993","multithreading","22656","2009-03-23T21:53:54Z"]]},"text/plain":"<Spark SQL result set with 10 rows and 4 fields>"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":true},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"b806b1f7-1a05-43c3-a455-b2017da78466"},{"cell_type":"code","source":["table_name = 'dim_votes'\r\n","\r\n","dfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\r\n","dfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\r\n","dfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\r\n","\r\n","dfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\r\n","dfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\r\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d0efd028-5e97-48c6-926c-4dbda580af1c","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2023-07-27T11:58:35.8296492Z","session_start_time":null,"execution_start_time":"2023-07-27T11:58:36.3160741Z","execution_finish_time":"2023-07-27T11:58:48.9191217Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":8,"UNKNOWN":0},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4345,"rowCount":50,"usageDescription":"","jobId":30,"name":"toString at String.java:2994","description":"Delta: Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n: Compute snapshot for version: 0","submissionTime":"2023-07-27T11:58:48.055GMT","completionTime":"2023-07-27T11:58:48.154GMT","stageIds":[42,43,41],"jobGroup":"10","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":51,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4345,"dataRead":1568,"rowCount":54,"usageDescription":"","jobId":29,"name":"toString at String.java:2994","description":"Delta: Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n: Compute snapshot for version: 0","submissionTime":"2023-07-27T11:58:47.346GMT","completionTime":"2023-07-27T11:58:48.034GMT","stageIds":[39,40],"jobGroup":"10","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":1568,"dataRead":1504,"rowCount":8,"usageDescription":"","jobId":28,"name":"toString at String.java:2994","description":"Delta: Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n: Compute snapshot for version: 0","submissionTime":"2023-07-27T11:58:47.123GMT","completionTime":"2023-07-27T11:58:47.196GMT","stageIds":[38],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":27,"name":"","description":"Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T11:58:46.485GMT","completionTime":"2023-07-27T11:58:46.485GMT","stageIds":[],"jobGroup":"10","status":"SUCCEEDED","numTasks":0,"numActiveTasks":0,"numCompletedTasks":0,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":0,"numActiveStages":0,"numCompletedStages":0,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":42326068,"dataRead":56713321,"rowCount":20286728,"usageDescription":"","jobId":26,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T11:58:39.208GMT","completionTime":"2023-07-27T11:58:46.323GMT","stageIds":[37,36],"jobGroup":"10","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":56713321,"dataRead":47523001,"rowCount":20286728,"usageDescription":"","jobId":25,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T11:58:37.411GMT","completionTime":"2023-07-27T11:58:39.171GMT","stageIds":[35],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":23,"name":"load at NativeMethodAccessorImpl.java:0","description":"Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T11:58:36.665GMT","completionTime":"2023-07-27T11:58:36.699GMT","stageIds":[33],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":22,"name":"load at NativeMethodAccessorImpl.java:0","description":"Job group for statement 10:\ntable_name = 'dim_votes'\n\ndfVotes = spark.read.format(\"parquet\").load('Tables/Votes')\ndfVoteTypes = spark.read.format(\"parquet\").load('Tables/VoteTypes')\ndfVoteType = dfVotes.join(dfVoteTypes,dfVotes.VoteTypeId == dfVoteTypes.Id, how='Inner')\ndfOutputColumns = dfVoteType.select(dfVoteType.PostId, dfVoteType.UserId, dfVoteType.BountyAmount, dfVoteType.Name)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T11:58:36.517GMT","completionTime":"2023-07-27T11:58:36.554GMT","stageIds":[32],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"d02f6f92-2196-4293-816e-061259ab9cb4"},"text/plain":"StatementMeta(, d0efd028-5e97-48c6-926c-4dbda580af1c, 10, Finished, Available)"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"680ecdf1-688e-4314-a0fb-722df6028c8f"},{"cell_type":"code","source":["table_name = 'dim_user'\r\n","\r\n","dfUsers = spark.read.format(\"parquet\").load('Tables/Users')\r\n","dfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\r\n","\r\n","dfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\r\n","\r\n","dfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\r\n","dfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d0efd028-5e97-48c6-926c-4dbda580af1c","statement_id":15,"state":"finished","livy_statement_state":"available","queued_time":"2023-07-27T12:27:09.7771372Z","session_start_time":null,"execution_start_time":"2023-07-27T12:27:10.4153182Z","execution_finish_time":"2023-07-27T12:27:17.3490302Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":8,"UNKNOWN":0},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4353,"rowCount":50,"usageDescription":"","jobId":55,"name":"toString at String.java:2994","description":"Delta: Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name): Compute snapshot for version: 1","submissionTime":"2023-07-27T12:27:16.302GMT","completionTime":"2023-07-27T12:27:16.333GMT","stageIds":[74,75,76],"jobGroup":"15","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":52,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4353,"dataRead":3467,"rowCount":58,"usageDescription":"","jobId":54,"name":"toString at String.java:2994","description":"Delta: Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name): Compute snapshot for version: 1","submissionTime":"2023-07-27T12:27:15.717GMT","completionTime":"2023-07-27T12:27:16.281GMT","stageIds":[72,73],"jobGroup":"15","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":2,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":3467,"dataRead":3281,"rowCount":16,"usageDescription":"","jobId":53,"name":"toString at String.java:2994","description":"Delta: Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name): Compute snapshot for version: 1","submissionTime":"2023-07-27T12:27:15.513GMT","completionTime":"2023-07-27T12:27:15.581GMT","stageIds":[71],"jobGroup":"15","status":"SUCCEEDED","numTasks":2,"numActiveTasks":0,"numCompletedTasks":2,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":2,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":1768,"rowCount":3,"usageDescription":"","jobId":52,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)","submissionTime":"2023-07-27T12:27:14.757GMT","completionTime":"2023-07-27T12:27:14.958GMT","stageIds":[70,69],"jobGroup":"15","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":7728191,"dataRead":32505817,"rowCount":2168904,"usageDescription":"","jobId":51,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)","submissionTime":"2023-07-27T12:27:12.666GMT","completionTime":"2023-07-27T12:27:14.593GMT","stageIds":[67,68],"jobGroup":"15","status":"SUCCEEDED","numTasks":6,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":5,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":32505817,"dataRead":3458613,"rowCount":2186471,"usageDescription":"","jobId":50,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)","submissionTime":"2023-07-27T12:27:11.629GMT","completionTime":"2023-07-27T12:27:12.627GMT","stageIds":[66],"jobGroup":"15","status":"SUCCEEDED","numTasks":5,"numActiveTasks":0,"numCompletedTasks":5,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":5,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":48,"name":"load at NativeMethodAccessorImpl.java:0","description":"Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)","submissionTime":"2023-07-27T12:27:10.644GMT","completionTime":"2023-07-27T12:27:10.681GMT","stageIds":[64],"jobGroup":"15","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":47,"name":"load at NativeMethodAccessorImpl.java:0","description":"Job group for statement 15:\ntable_name = 'dim_user'\n\ndfUsers = spark.read.format(\"parquet\").load('Tables/Users')\ndfBadges = spark.read.format(\"parquet\").load('Tables/Badges')\n\ndfUserBadge = dfUsers.join(dfBadges, dfUsers.Id == dfBadges.UserId, how='Inner')\n\ndfOutputColumns = dfUserBadge.select(dfUserBadge.DisplayName, dfUserBadge.Age, dfUserBadge.Location, dfUserBadge.Name, dfUserBadge.UserId)\ndfOutputColumns.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)","submissionTime":"2023-07-27T12:27:10.493GMT","completionTime":"2023-07-27T12:27:10.530GMT","stageIds":[63],"jobGroup":"15","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"923b38c1-8fae-47a7-9cdc-022f86800daa"},"text/plain":"StatementMeta(, d0efd028-5e97-48c6-926c-4dbda580af1c, 15, Finished, Available)"},"metadata":{}}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6db029fb-9186-493d-a330-40f2d93e024b"},{"cell_type":"code","source":["table_name = 'fact_post_comment'\r\n","\r\n","dfComment = spark.read.format(\"parquet\").load('Tables/Comments')\r\n","dfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\r\n","dfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\r\n","\r\n","dfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\r\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d0efd028-5e97-48c6-926c-4dbda580af1c","statement_id":23,"state":"finished","livy_statement_state":"available","queued_time":"2023-07-27T12:44:51.2393437Z","session_start_time":null,"execution_start_time":"2023-07-27T12:44:51.7065046Z","execution_finish_time":"2023-07-27T12:45:31.779791Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":10,"UNKNOWN":0},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4515,"rowCount":50,"usageDescription":"","jobId":89,"name":"toString at String.java:2994","description":"Delta: Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n: Compute snapshot for version: 1","submissionTime":"2023-07-27T12:45:29.528GMT","completionTime":"2023-07-27T12:45:29.563GMT","stageIds":[125,126,124],"jobGroup":"23","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":52,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4515,"dataRead":4854,"rowCount":58,"usageDescription":"","jobId":88,"name":"toString at String.java:2994","description":"Delta: Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n: Compute snapshot for version: 1","submissionTime":"2023-07-27T12:45:28.916GMT","completionTime":"2023-07-27T12:45:29.506GMT","stageIds":[122,123],"jobGroup":"23","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":2,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4854,"dataRead":7447,"rowCount":16,"usageDescription":"","jobId":87,"name":"toString at String.java:2994","description":"Delta: Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n: Compute snapshot for version: 1","submissionTime":"2023-07-27T12:45:28.725GMT","completionTime":"2023-07-27T12:45:28.785GMT","stageIds":[121],"jobGroup":"23","status":"SUCCEEDED","numTasks":2,"numActiveTasks":0,"numCompletedTasks":2,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":2,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2508,"rowCount":3,"usageDescription":"","jobId":86,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:45:28.099GMT","completionTime":"2023-07-27T12:45:28.216GMT","stageIds":[119,120],"jobGroup":"23","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":1171815722,"dataRead":1159453455,"rowCount":7750330,"usageDescription":"","jobId":85,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:45:08.634GMT","completionTime":"2023-07-27T12:45:27.972GMT","stageIds":[117,118,115,116],"jobGroup":"23","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":53,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":3,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":1159453455,"dataRead":1952795649,"rowCount":11479543,"usageDescription":"","jobId":84,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:45:03.052GMT","completionTime":"2023-07-27T12:45:08.593GMT","stageIds":[114,112,113],"jobGroup":"23","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":34,"numSkippedTasks":19,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":34,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":500862536,"dataRead":444500270,"rowCount":7750366,"usageDescription":"","jobId":83,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:44:52.115GMT","completionTime":"2023-07-27T12:44:59.681GMT","stageIds":[111],"jobGroup":"23","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":1451933113,"dataRead":1327363930,"rowCount":7458390,"usageDescription":"","jobId":82,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:44:52.087GMT","completionTime":"2023-07-27T12:45:03.010GMT","stageIds":[110],"jobGroup":"23","status":"SUCCEEDED","numTasks":11,"numActiveTasks":0,"numCompletedTasks":11,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":11,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at <unknown>:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":81,"name":"load at <unknown>:0","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:44:51.876GMT","completionTime":"2023-07-27T12:44:51.905GMT","stageIds":[109],"jobGroup":"23","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"load at <unknown>:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":80,"name":"load at <unknown>:0","description":"Job group for statement 23:\ntable_name = 'fact_post_comment'\n\ndfComment = spark.read.format(\"parquet\").load('Tables/Comments')\ndfPost = spark.read.format(\"parquet\").load(\"Tables/Posts\")\ndfPostComment = dfPost.join(dfComment, dfPost.Id == dfComment.PostId, how='Inner').select(dfPost.OwnerUserId, dfPost.Id, dfPost.AcceptedAnswerId, dfPost.AnswerCount,dfPost.Body, dfPost.ClosedDate,dfPost.CommentCount, dfPost.CreationDate,dfPost.LastActivityDate,dfPost.PostTypeId,dfPost.Score, dfPost.Title, dfPost.Tags, dfComment.CreationDate.alias(\"CommentDate\"), dfComment.Score.alias(\"CommentScore\"), dfComment.Text.alias(\"CommentText\"), dfComment.UserId.alias(\"CommentUser\"))\n\ndfPostComment.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").format(\"delta\").save(\"Tables/\" + table_name)\n","submissionTime":"2023-07-27T12:44:51.735GMT","completionTime":"2023-07-27T12:44:51.763GMT","stageIds":[108],"jobGroup":"23","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"dba8da38-49c3-4b4c-aa2d-a2642e958977"},"text/plain":"StatementMeta(, d0efd028-5e97-48c6-926c-4dbda580af1c, 23, Finished, Available)"},"metadata":{}}],"execution_count":21,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"c1c0e78a-6e5c-48e0-9e11-f1664782bd8b\",\"activityId\":\"d0efd028-5e97-48c6-926c-4dbda580af1c\",\"applicationId\":\"application_1690455602133_0001\",\"jobGroupId\":\"23\",\"advices\":{\"warn\":1}}"}},"id":"26921692-525f-4e9c-ba8b-07c53d75d674"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{"3b148e3c-56aa-4d95-adbc-17b31f75eef6":{"type":"Synapse.DataFrame","sync_state":{"table":{"rows":[{"0":"210312","1":"Great Question","2":"22656","3":"2009-01-14 01:47:38.497","index":1},{"0":"212842","1":"Stellar Question","2":"22656","3":"2009-01-17 00:12:50.957","index":2},{"0":"237576","1":"generics","2":"22656","3":"2009-02-04 18:10:30.347","index":3},{"0":"237577","1":"linq","2":"22656","3":"2009-02-11 12:03:15.57","index":4},{"0":"260322","1":"vb.net","2":"22656","3":"2009-03-27 13:25:55.147","index":5},{"0":"298540","1":"performance","2":"22656","3":"2009-04-24 15:48:44.087","index":6},{"0":"366516","1":"linq","2":"22656","3":"2009-07-01 20:08:44.637","index":7},{"0":"367882","1":"reflection","2":"22656","3":"2009-06-30 15:11:41.813","index":8},{"0":"371328","1":"string","2":"22656","3":"2009-06-23 19:31:10.993","index":9},{"0":"375993","1":"multithreading","2":"22656","3":"2009-03-23 21:53:54.427","index":10}],"schema":[{"key":"0","name":"Id","type":"bigint"},{"key":"1","name":"Name","type":"string"},{"key":"2","name":"UserId","type":"bigint"},{"key":"3","name":"Date","type":"timestamp"}],"truncated":false},"isSummary":false,"language":"scala"},"persist_state":{"view":{"type":"details","tableOptions":{},"chartOptions":{"chartType":"bar","categoryFieldKeys":["1"],"seriesFieldKeys":["1"],"aggregationType":"count","isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}}}}},"trident":{"lakehouse":{"default_lakehouse":"f1f27e23-4e5d-4147-bfb9-de187b982eff","known_lakehouses":[{"id":"f1f27e23-4e5d-4147-bfb9-de187b982eff"}],"default_lakehouse_name":"LH_AXIANS_DEMO","default_lakehouse_workspace_id":"a6df6f51-7555-4607-a7a8-b56e284c62d1"}}},"nbformat":4,"nbformat_minor":5}